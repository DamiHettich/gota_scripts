{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from campitos import campos, errores\n",
    "from create_tables import *\n",
    "import csv\n",
    "import json\n",
    "\n",
    "def csv_to_fixture(csv_path, model_name):\n",
    "    with open(csv_path, 'r') as f:\n",
    "        reader = csv.DictReader(f)\n",
    "        fixtures = []\n",
    "        for row in reader:\n",
    "            fixture = {\n",
    "                'model': model_name,\n",
    "                'pk': int(row['pk']),  # Asume que 'pk' es una columna en tu CSV\n",
    "                'fields': {field: value for field, value in row.items() if field != 'pk'}\n",
    "            }\n",
    "            fixtures.append(fixture)\n",
    "    return fixtures\n",
    "\n",
    "def merge_fixtures(fixtures, output_path):\n",
    "    \"\"\"\n",
    "    Merge a list of fixture dictionaries into a single fixture file.\n",
    "\n",
    "    Args:\n",
    "        fixtures (list): A list of fixture dictionaries.\n",
    "        output_path (str or Path): The path to the output file.\n",
    "\n",
    "    Returns:\n",
    "        None\n",
    "    \"\"\"\n",
    "    merged = []\n",
    "    for fixture in fixtures:\n",
    "        merged.extend(fixture)\n",
    "    with open(output_path, 'w') as f:\n",
    "        json.dump(merged, f, indent=4)\n",
    "\n",
    "def full_sheet(pumps, zones, horizons):\n",
    "    sheet = pumps.merge(zones, on=['pump','field'], how='inner').merge(horizons, on=['field','pump','zone'], how='inner')\n",
    "    sheet = sheet[['field','pk_x','pump','pk_y','zone','pk','h_level']]\n",
    "    sheet = sheet.rename(columns={'pk_x': 'pump_id', 'pk_y': 'zone_id', 'pk':'horizon_id'})\n",
    "    return sheet\n",
    "\n",
    "def etl_loop_error(campos):\n",
    "    for i, field in enumerate(campos):\n",
    "        print(f'working on {field}')\n",
    "        id_db = campos[field]['id']\n",
    "        id = campos[field]['spreadsheet_id']\n",
    "        if i == 0:\n",
    "            fields = fields_table(id, id_db)\n",
    "            fields['name'] = field \n",
    "            z, p = zone_and_pump_tables(id, id_db)\n",
    "            h = horizon_table(id, id_db)\n",
    "        else:\n",
    "            fields2 = fields_table(id, id_db)\n",
    "            fields2['name'] = field\n",
    "            fields = pd.concat([fields,fields2]).reset_index(drop=True)\n",
    "            z2, p2 = zone_and_pump_tables(id, id_db)\n",
    "            z = pd.concat([z, z2]).reset_index(drop=True)\n",
    "            p = pd.concat([p, p2]).reset_index(drop=True)\n",
    "            h2 = horizon_table(id, id_db)\n",
    "            h = pd.concat([h, h2]).reset_index(drop=True)\n",
    "    \n",
    "    return fields, p, z, h\n",
    "\n",
    "def etl_loop(campos):\n",
    "    for i, field in enumerate(campos):\n",
    "        print(f'working on {field}')\n",
    "        try:\n",
    "            \n",
    "            id_db = campos[field]['id']\n",
    "            id = campos[field]['spreadsheet_id']\n",
    "            if i == 0:\n",
    "                fields = fields_table(id, id_db)\n",
    "                fields['name'] = field \n",
    "                z, p = zone_and_pump_tables(id, id_db)\n",
    "                h = horizon_table(id, id_db)\n",
    "            else:\n",
    "                fields2 = fields_table(id, id_db)\n",
    "                fields2['name'] = field\n",
    "                fields = pd.concat([fields,fields2]).reset_index(drop=True)\n",
    "                z2, p2 = zone_and_pump_tables(id, id_db)\n",
    "                z = pd.concat([z, z2]).reset_index(drop=True)\n",
    "                p = pd.concat([p, p2]).reset_index(drop=True)\n",
    "                h2 = horizon_table(id, id_db)\n",
    "                h = pd.concat([h, h2]).reset_index(drop=True)\n",
    "        except Exception:\n",
    "            print('error on field')\n",
    "\n",
    "    return fields, p, z, h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on Bellavista 1\n",
      "working on Bellavista 2\n",
      "working on Culenar\n",
      "working on Colin\n",
      "working on El Sauce\n",
      "working on La Capilla\n",
      "working on Las Delicias\n",
      "error on field\n",
      "working on Longavi 1\n",
      "working on Longavi 2\n",
      "working on Longavi 3\n",
      "working on Longavi 4\n",
      "working on Las Liras\n",
      "working on Las Nueces\n",
      "working on Liguana\n",
      "working on Los Maitenes\n",
      "working on Morza\n",
      "working on Naguilan\n",
      "working on Odessa\n",
      "working on Peñaflor 1\n",
      "working on Peñaflor 2\n",
      "working on Piemonte\n",
      "working on Pullami Sauce\n",
      "working on Pullami Aromo\n",
      "working on Pullami Candelaria\n",
      "working on Pullami Bulnes\n",
      "working on Quillayes\n",
      "working on Rauco\n",
      "working on Rancho\n",
      "working on San Agustin\n",
      "working on San Jose 1\n",
      "working on San Jose 2\n",
      "working on San Jose 3\n",
      "working on San Ramon 1\n",
      "working on San Ramon 2\n",
      "working on San Ramon 3\n",
      "working on San Juan\n",
      "working on Santa Magdalena\n",
      "working on Teno\n",
      "working on Torca 1\n",
      "working on Torca 2\n",
      "working on Trinidad\n",
      "working on Vitacura\n"
     ]
    }
   ],
   "source": [
    "fields, p, z, h = etl_loop(campos)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "basics = fields[['basic_field', 'name']]\n",
    "basics = basics.rename(columns={'basic_field':'pk'})\n",
    "\n",
    "fields= fields.drop(columns='name')\n",
    "fields = fields.reset_index().rename(columns={'index':'pk'})\n",
    "fields['pk'] = fields['pk'] +1\n",
    "\n",
    "p = p.reset_index().rename(columns={'index':'pk'})\n",
    "p['pk'] = p['pk'] +1\n",
    "\n",
    "h = h.reset_index().rename(columns={'index':'pk'})\n",
    "h['pk'] = h['pk'] +1\n",
    "\n",
    "z = z.reset_index().rename(columns={'index':'pk'})\n",
    "z['pk'] = z['pk'] +1\n",
    "\n",
    "\n",
    "cols_zone = ['rendimiento ton','rendimiento/ha','Nombre','ADP','superficie_sector.1','Cuartel','Rendimiento/ ha','variedad','tesis','Aforo_1']\n",
    "for col in cols_zone:\n",
    "    if col in z.columns:\n",
    "        z = z.drop(columns=[col])\n",
    "\n",
    "\n",
    "fields.to_csv('./csvs/fields.csv', index=False)\n",
    "basics.to_csv('./csvs/b.csv',index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "h_map = full_sheet(p,z,h)\n",
    "\n",
    "z_map = h_map.groupby(['field','pump','zone']).first().reset_index().sort_values(['pump_id', 'zone_id'])\n",
    "z_map = z_map[['field','pump','pump_id','zone','zone_id']]\n",
    "\n",
    "p_map = z_map.groupby(['field','pump_id']).first().reset_index().sort_values(['pump_id'])\n",
    "p_map = p_map[['field','pump','pump_id']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "zp = z.merge(z_map, on=['pump','zone','field']).drop(columns=['pump', 'zone_id']).rename(columns={'pump_id':'pump', 'zone':'zone_number'})\n",
    "hp = h.merge(h_map, on=['pump','zone','field', 'h_level']).drop(columns=['pump','zone','horizon_id','pump_id', 'field']).rename(columns={'zone_id':'zone'})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "p = p.rename(columns={'pump':'name'})\n",
    "p.to_csv('./csvs/p.csv', index=False)\n",
    "zp.to_csv('./csvs/z.csv', index=False)\n",
    "hp.to_csv('./csvs/h.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "fixtures = [\n",
    "    csv_to_fixture('./csvs/b.csv', 'gota_app.basicfield'),\n",
    "    csv_to_fixture('./csvs/fields.csv', 'gota_app.seasonfield'),\n",
    "    csv_to_fixture('./csvs/p.csv', 'gota_app.pump'),\n",
    "    csv_to_fixture('./csvs/z.csv', 'gota_app.zone'),\n",
    "    csv_to_fixture('./csvs/h.csv', 'gota_app.horizon'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "merge_fixtures(fixtures, 'data.json')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "working on Pullami Sauce\n",
      "working on Los Maitenes\n"
     ]
    }
   ],
   "source": [
    "\n",
    "fields, p, z, h = etl_loop_error(errores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th>INFORMACION</th>\n",
       "      <th>weather_factor</th>\n",
       "      <th>rain_factor</th>\n",
       "      <th>dropcontrol_id</th>\n",
       "      <th>day_starttime</th>\n",
       "      <th>delay</th>\n",
       "      <th>weekday</th>\n",
       "      <th>weather_station</th>\n",
       "      <th>season</th>\n",
       "      <th>basic_field</th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>1019</td>\n",
       "      <td>08:00</td>\n",
       "      <td>10</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>23</td>\n",
       "      <td>Pullami Sauce</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0.6</td>\n",
       "      <td>479</td>\n",
       "      <td>8:00</td>\n",
       "      <td>15</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>15</td>\n",
       "      <td>Los Maitenes</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "INFORMACION weather_factor rain_factor dropcontrol_id day_starttime delay  \\\n",
       "0                        0         0.6           1019         08:00    10   \n",
       "1                        0         0.6            479          8:00    15   \n",
       "\n",
       "INFORMACION weekday  weather_station  season  basic_field           name  \n",
       "0                 1                1       1           23  Pullami Sauce  \n",
       "1                 4                1       1           15   Los Maitenes  "
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fields"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.8.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
